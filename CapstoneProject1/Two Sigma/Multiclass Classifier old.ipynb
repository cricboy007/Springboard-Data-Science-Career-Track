{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T01:23:13.439900Z",
     "start_time": "2018-08-02T01:23:03.472697Z"
    },
    "_cell_guid": "317d7a86-7851-cb29-843d-96899eeecdcd",
    "_uuid": "fe5f0fb9d12babdb5eb35a4c7a0c72cb2ab3cb96",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "train = pd.read_json(r\"C:\\JupyterNotebooks\\Two Sigma\\train.json\")\n",
    "test = pd.read_json(r\"C:\\JupyterNotebooks\\Two Sigma\\test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T01:23:13.481018Z",
     "start_time": "2018-08-02T01:23:13.443914Z"
    },
    "_cell_guid": "ed645430-1c9d-36db-24cc-b09f8e02720a",
    "_uuid": "eff9358c107ff0a06cfd45cc1180fba50a2827c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 49352 rows and 15 attributes.\n",
      "49352\n",
      "There are 74659 rows and 14 attributes.\n"
     ]
    }
   ],
   "source": [
    "print (f'There are {train.shape[0]} rows and {train.shape[1]} attributes.')\n",
    "print (len(train['listing_id'].unique()))\n",
    "train = train.set_index('listing_id')\n",
    "print (f'There are {test.shape[0]} rows and {test.shape[1]} attributes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T01:23:22.994526Z",
     "start_time": "2018-08-02T01:23:13.486031Z"
    },
    "_cell_guid": "b5b37d9f-7d46-9c10-172b-1f73cf418817",
    "_uuid": "02b5c8b831fecbe75c2c5637fa6a737cc62a6e74",
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 49352 rows and 15 attributes.\n",
      "49352\n",
      "There are 74659 rows and 14 attributes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "train = pd.read_json(r\"C:\\JupyterNotebooks\\Two Sigma\\train.json\")\n",
    "test = pd.read_json(r\"C:\\JupyterNotebooks\\Two Sigma\\test.json\")\n",
    "\n",
    "print (f'There are {train.shape[0]} rows and {train.shape[1]} attributes.')\n",
    "train = train.set_index('listing_id')\n",
    "print (f'There are {test.shape[0]} rows and {test.shape[1]} attributes.')\n",
    "\n",
    "def pre_processing(data):\n",
    "       \n",
    "    data['nb_images'] = data['photos'].apply(len)\n",
    "    data['nb_features'] = data['features'].apply(len)\n",
    "    data['nb_description'] = data['description'].apply(lambda x: len(x.split(' ')))\n",
    "    data['description_len'] = data['description'].apply(len)\n",
    "    \n",
    "    def room_price(x, y):\n",
    "        if y == 0:\n",
    "            return 0\n",
    "        return x/y\n",
    "    \n",
    "    def sentiment_analysis(x):\n",
    "        if len(x) == 0:\n",
    "            return 0\n",
    "        return TextBlob(x[0]).sentiment.polarity\n",
    "    \n",
    "    data = data.join(data['description'].apply(\n",
    "                         lambda x: TextBlob(x).sentiment.polarity).rename('sentiment'))\n",
    "    data['price_room'] = data.apply(lambda row: \n",
    "                                    room_price(row['price'],row['bedrooms']), axis=1)\n",
    "       \n",
    "    return data[important_features]\n",
    "\n",
    "def print_scores(test_name, train, test):\n",
    "    print ('{0} train score: {1}\\n{0} test score: {2}\\n'.format(test_name,\n",
    "                                                               train,\n",
    "                                                               test))\n",
    "\n",
    "def classification(train_data, test_data, target, test_size=0.2, random_state=19):    \n",
    "    # Split data into X and y\n",
    "    X = train_data\n",
    "    y = target\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,\n",
    "                                                        random_state=random_state)\n",
    "    \n",
    "    # Support vector machine\n",
    "    svm_model = svm.SVC(decision_function_shape='ovo', tol=0.00000001)\n",
    "    svm_model = svm_model.fit(X_train, y_train)\n",
    "    print_scores(\"Support Vector Machine\",\n",
    "                 svm_model.score(X_train, y_train),\n",
    "                 accuracy_score(y_test, svm_model.predict(X_test)))\n",
    "\n",
    "    # Random Forest\n",
    "    random_forest = RandomForestClassifier(n_estimators=10)\n",
    "    random_forest = random_forest.fit(X_train, y_train)\n",
    "    print_scores(\"Random Forest\",\n",
    "                 random_forest.score(X_train, y_train),\n",
    "                 accuracy_score(y_test, random_forest.predict(X_test)))\n",
    "\n",
    "    # GradientBoostingClassifier\n",
    "    gradientB_model = GradientBoostingClassifier(n_estimators=20,\n",
    "                                      learning_rate=1.0,\n",
    "                                      max_depth=1,\n",
    "                                      random_state=0).fit(X_train, y_train)\n",
    "    gradientB_model = gradientB_model.fit(X_train, y_train)\n",
    "    print_scores(\"Gradient Boosting Classifier\",\n",
    "                 gradientB_model.score(X_train, y_train),\n",
    "                 accuracy_score(y_test, gradientB_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T01:23:23.003433Z",
     "start_time": "2018-08-02T01:23:22.998419Z"
    }
   },
   "outputs": [],
   "source": [
    "global important_features\n",
    "important_features = ['bathrooms', 'bedrooms', 'price', 'price_room',\n",
    "                      'latitude','longitude', 'nb_images','nb_features',\n",
    "                      'sentiment', 'nb_description', 'description_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T01:25:23.967537Z",
     "start_time": "2018-08-02T01:23:23.015508Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_train_data = pre_processing(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T01:25:23.991730Z",
     "start_time": "2018-08-02T01:25:23.971945Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_train_data = processed_train_data[['bathrooms', 'bedrooms', 'price', 'price_room',\n",
    "                            'latitude','longitude', 'nb_images','nb_features', \n",
    "                            'nb_description', 'description_len','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T01:28:24.892538Z",
     "start_time": "2018-08-02T01:25:23.996118Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_test_data = pre_processing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T02:07:20.727103Z",
     "start_time": "2018-08-02T01:28:24.895545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine train score: 0.969251032142043\n",
      "Support Vector Machine test score: 0.7070205652922703\n",
      "\n",
      "Random Forest train score: 0.9625896000607888\n",
      "Random Forest test score: 0.7126937493668322\n",
      "\n",
      "Gradient Boosting Classifier train score: 0.7040095235682987\n",
      "Gradient Boosting Classifier test score: 0.704386586971938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = train['interest_level']  \n",
    "classification(processed_train_data, processed_test_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
